Since this is an early stage project, I decided to write a development log instead of a change log. The history of every design and feature decision will be described here.
2015-05-09
I may need to reconsider how the persisters are done. At first I designed it that way to make it easier to switch data
stores. I don't think I need to be able to do that anymore. Creating notes uses a newer pattern that I think I'd prefer.
On another note, I decided to quickly add a new feature that I need almost a little more than a screener: a place for
notes on companies I'm already invested in or am investigating. I once tried this a while ago with something really
ambitious. For now though, a basic text blob store will suffice. I'll add onto it as I need to.
Plus, this is the perfect opportunity to start playing around with ReactJS. I'm going to want a web UI anyway to manage
the scraper and parsing.

2015-04-26
I can think of two ways to develop the screener. One is the just have a function for each criteria and then having the
caller manage narrowing data with multiple criteria. The other is to use criteria objects and have the caller pass those
into the screener. The advantage of the latter is that it makes the data layer a little more abstract. With mysql, I can
optimize a little by having a union query on several of those screeners where with the first solution, it is guaranteed
to be one query per criteria which will return more rows that the application code will have to parse.
I'm actually going to go with the first one though because it is much simpler. I may not need the complexity of criteria
objects since my data set isn't going to be THAT large and I don't need fast response times either. Also, the simpler
solution can be refactored pretty easily into the complex one if it turns out that I do need it

2015-04-07:
I gave MongoDB a real shot. Unfortunately writing complex queries reminds me of coding in LISP, but with curly braces instead. 
Not to mention that the most widely used go library for it is cumbersome. As much as I wanted to try a new technology, I feel
like I spent enough time in MongoDB to justify not liking and at this point I want to see more development velocity.

2015-02-16:
The structure of XBRL filings is definitely more complex than I anticipated. I suspect that there are more variations than I was
hoping there would be. More research into XBRL for SEC filings did not reveal anything promising other than confirm my fears.
Decisions are best made with data however. My current parser can successfully parse 1600 out of 17,000 filings in 2011. This is
a pretty low success rate. However, I can probably still get a large chunk of that parsed by continuing with the current
architecture. I don't need 100% success rate. In fact, since this is only meant to be an aid, not a replacement, for human
decision making, I only need a large sample of data to help me find stocks to look deeper at. With that logic, even 10% success
may be adequate.
I won't know for sure until I start using the tool. That means moving on and finishing the 0.1 feature set, which is just the 
screener now.

Inital Log Entry:
Taken from blog post http://www.professorbeekums.com/2015/02/daunting-problems.html
A few months ago I started to write a tool that would help me research stocks. I had used tools like Google Finance, Yahoo Finance, my brokerage, etc, which where great for a while. Eventually I wanted features that they didn't provide (such as screening different types of data). I figured that they all get their data from somewhere and that place is probably the SEC. Given that the SEC is government, that data is probably free to access!
So I do some digging and I find that all the data I wanted and more is there. Immediately I start imagining all the things I want to do: screen more data, flag all the previous companies executives at a company were in charge of, custom dashboards, maybe even a recommendation engine for myself. Then I look at the data. There is all the data I want and more. The more part is the kicker. There is a lot of data, in different formats, and how can I possibly parse all of it by myself?
Like any big problem, the first thing to do is break it down into smaller pieces. With software projects, that's your minimum viable product. Mine boiled down to 2 pieces: retrieving quarterly/annual filings and parsing those filings. The usefulness of the project was everything else, especially the custom screeners, but those 2 pieces are the foundation for everything else. Other major software pieces like a data store, logging, file storage, etc are thing I know how to do well and can implement as I need them. I first needed to focus on the things I didn't know and that was getting and parsing those filings.
So now I only have 2 things I need to implement, things should be easy right? Wrong. Not every company filed things the same way apparently. There's no "quick start" or convenient documentation for people trying this. The SEC isn't exactly a startup that needs to rapidly accrue users before it runs out of cash. There also isn't exactly a lot of demand for this outside of financial institutions who pay people to do this. The documentation that does exist is spread out over many different web sites and difficult to read. It would take me months to fully grasp all of the standards and formats being used. That would be a frustrating experience and with no code to show for it in that time, I would lose interest.
The next step then is to reduce the problem into an even smaller step: just parsing the data for a single company and verifying that the data is correct. Once I had that, I can then attempt to parse every filing under the assumption that it would follow that format. Obviously this is the wrong assumption, but then I can log the failures. New code can be written to account for those failures. Test code can be written to make sure I don't create regression bugs along the way.
The main risk with this strategy is that I could lead myself down a rabbit hole and build a system that just inherently doesn't work since I'm building it using trial and error instead of fully understanding everything. In fact, I've already had to hit that with 3 or 4 refactors of my parser. However, the risk was well worth it. Even with refactors, I'm still learning as I work around the problem. Making some progress, even if I have to undo some previous work, is better than standing still. Code can be isolated so that rework is minimized. Also this same risk would still have existed if I spent the initial months reading documentation because I could have easily misinterpreted something in there or the documentation I read could have been incorrect. Nothing is more definitive than running code to see what happens.